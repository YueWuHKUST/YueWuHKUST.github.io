<!DOCTYPE html>

<html>

<head lang="en">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>AniFaceGAN</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="./files/bootstrap.min.css">
    <link rel="stylesheet" href="./files/font-awesome.min.css">
    <link rel="stylesheet" href="./files/codemirror.min.css">
    <link rel="stylesheet" href="./files/app.css">




</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-20 text-center">
                <br></br>
                Animatable 3D-Aware Face Image Generation for Realistic Video Avatars <br>
                <small>
                    
                </small>
            </h1>
            <hr style="margin-top:0px">
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
					<li>
                        <a style="font-size: 16px;">
                            Yue Wu
                        </a>
                        <sup>1,2</sup>
                    </li>
                    <li>
                        <a href="https://yudeng.github.io/" style="font-size: 16px;">
                            Yu Deng
                        </a>
                        <sup>2</sup>
                    </li>
					          <li>
                        <a href="https://jlyang.org/" style="font-size: 16px;">
                            Jiaolong Yang
                        </a>
                        <sup>2</sup>
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=-ncz2s8AAAAJ&hl=en" style="font-size: 16px;">
                            Fangyun Wei
                        </a>
                        <sup>2</sup>
                    </li>
                    <li>
                        <a href="https://cqf.io/" style="font-size: 16px;">
                            Qifeng Chen
                        </a>
                        <sup>1</sup>
                    </li>
                    <li>
                        <a href="http://www.xtong.info/" style="font-size: 16px;">
                            Xin Tong
                        </a>
                        <sup>2</sup>
                    </li><br>
                    <a></a><br>
					<li>
                        <sup>1</sup>
                        <a href="https://hkust.edu.hk/" style="font-size: 16px;">
                            Hong Kong University of Science and Technology
                        </a>
                    </li>
					<li>
                        <sup>2</sup>
                        <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/"
                            style="font-size: 16px;">
                            Microsoft Research Asia
                        </a>
                    </li>
                    <li>
              
                    </li>
                </ul>
            </div>
        </div>
		
		<br />
		<div class="row">
		<div class="col-md-12 text-center">
<!-- 			<a href="https://arxiv.org/abs/2206.07255" target="blank"><span style="text-decoration:underline;font-size:20px">arXiv:2206.07255</span></a> -->
		</div>
		</div>

<!--
        <div class="row">
            <div class="col-md-4 col-md-offset-4 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="https://YuDeng.github.io/GRAM/files/compressed_new.pdf">
                            <img src="./files/paper.png" height="60px">
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>

                    <li>
                        <a href="https://arxiv.org/abs/2112.08867">
                            <img src="./files/arxiv.png" height="60px">
                            <h4><strong>ArXiv</strong></h4>
                        </a>
                    </li>

                    <li>
                        <a onClick="alert('Code coming soon!\nContact t-yudeng@microsoft.com for more details.')">
                            <img src="./files/github.png" height="60px">
                            <h4><strong>Code</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div>
-->
        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
			<!--
                <a>
                    <video style="width:100%;height:100%;" playsinline autoplay loop preload muted>
                        <source src="./files/teaser.mp4" type="video/mp4">
                    </video>
                </a>
			-->
                <br></br>
			
                <h2>
                    Abstract
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    Face image generation and animation have been a longstanding task. Although many 2D generative models yield excellent manipulations in 2D space, they often suffer from 3D inconsistency and undesirable artifacts when rendering from different camera viewpoints, and thus are not suitable for animations in video. Recently, 3D-aware GANs extend 2D GANs by using underlying 3D representations. Although these methods can preserve the 3D consistency across different viewpoints, they cannot achieve fine-grained control over attributes, most importantly, facial expression. In this paper, we propose an animatable 3D-aware face image generation method. Our framework mainly consists of a template implicit field and a 3D deformation field. The template field represents the canonical space and is shared across the same identity. Different expressions can be generated by deforming the manifolds in the target space to the canonical space. We enforce the generation to follow a prior 3D face parametric model by incorporating 3D-level imitative learning to encourage the deformation field to follow 3D prioris. Experiments show our method can produce high-quality animatable video avatars with strong visual 3D consistency.
                </p>
            </div>
        </div>

<!--         <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Video
                </h2>
                <hr style="margin-top:0px">
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/Uqzs4uN6v8M" allowfullscreen=""
                            style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->
        
        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
				<!--
                <h2>
                    Acknowledgements
                </h2>
				-->
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    The website template was adapted from <a href="https://yudeng.github.io/GRAM/">GRAM</a> and <a href="https://jonbarron.info/mipnerf/">Mip-NeRF</a>.
                </p>
            </div>
        </div>


</body>

</html>



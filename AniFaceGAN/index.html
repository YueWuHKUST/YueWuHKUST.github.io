<!DOCTYPE html>

<html>

<head lang="en">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>AniFaceGAN</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="./files/bootstrap.min.css">
    <link rel="stylesheet" href="./files/font-awesome.min.css">
    <link rel="stylesheet" href="./files/codemirror.min.css">
    <link rel="stylesheet" href="./files/app.css">




</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-20 text-center">
                <br></br>
                AniFaceGAN: Animatable 3D-Aware Face Image Generation for Video Avatars <br>
                <small>
                    
                </small>
            </h1>
            <hr style="margin-top:0px">
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
					<li>
                        <a style="font-size: 16px;">
                            Yue Wu
                        </a>
                        <sup>1</sup>
                    </li>
                    <li>
                        <a href="https://yudeng.github.io/" style="font-size: 16px;">
                            Yu Deng
                        </a>
                        <sup>2</sup>
                    </li>
					          <li>
                        <a href="https://jlyang.org/" style="font-size: 16px;">
                            Jiaolong Yang
                        </a>
                        <sup>3</sup>
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=-ncz2s8AAAAJ&hl=en" style="font-size: 16px;">
                            Fangyun Wei
                        </a>
                        <sup>3</sup>
                    </li>
                    <li>
                        <a href="https://cqf.io/" style="font-size: 16px;">
                            Qifeng Chen
                        </a>
                        <sup>1</sup>
                    </li>
                    <li>
                        <a href="http://www.xtong.info/" style="font-size: 16px;">
                            Xin Tong
                        </a>
                        <sup>3</sup>
                    </li><br>
                    <a></a><br>
			<li>
                        <sup>1</sup>
                        <a href="https://hkust.edu.hk/" style="font-size: 16px;">
                            Hong Kong University of Science and Technology
                        </a>
                        </li>
			<li>
                        <sup>2</sup>
                        <a href="https://www.tsinghua.edu.cn/en/"
                            style="font-size: 16px;">
                             Tsinghua Unviersity
                        </a>
			<li>
                        <sup>2</sup>
                        <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/"
                            style="font-size: 16px;">
                            Microsoft Research Asia
                        </a>
                    </li>
                    <li>
              
                    </li>
                </ul>
            </div>
        </div>
		
		<br />
		<div class="row">
		<div class="col-md-12 text-center">
<!-- 			<a href="https://arxiv.org/abs/2206.07255" target="blank"><span style="text-decoration:underline;font-size:20px">arXiv:2206.07255</span></a> -->
		</div>
		</div>


        <div class="row">
            <div class="col-md-4 col-md-offset-4 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="https://arxiv.org/pdf/2210.06465.pdf">
                            <img src="./files/paper.png" height="60px">
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>

                    <li>
                        <a href="https://arxiv.org/abs/2210.06465">
                            <img src="./files/arxiv.png" height="60px">
                            <h4><strong>ArXiv</strong></h4>
                        </a>
                    </li>

<!--                     <li>
                        <a onClick="alert('Code coming soon!\nContact t-yudeng@microsoft.com for more details.')">
                            <img src="./files/github.png" height="60px">
                            <h4><strong>Code</strong></h4>
                        </a>
                    </li> -->
                </ul>
            </div>
        </div>
	
        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
			<!--
                <a>
                    <video style="width:100%;height:100%;" playsinline autoplay loop preload muted>
                        <source src="./files/teaser.mp4" type="video/mp4">
                    </video>
                </a>
			-->
                <br></br>
			
                <h2>
                    Abstract
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    Although 2D generative models have made great progress in face image generation and animation, they often suffer from undesirable artifacts such as 3D inconsistency when rendering images from different camera viewpoints. This prevents them from synthesizing video animations indistinguishable from real ones. Recently, 3D-aware GANs extend 2D GANs for explicit disentanglement of camera pose by leveraging 3D scene representations. These methods can well preserve the 3D consistency of the generated images across different views, yet they cannot achieve fine-grained control over other attributes, among which facial expression control is arguably the most useful and desirable for face animation.
In this paper, we propose an animatable 3D-aware GAN for multiview consistent face animation generation. The key idea is to decompose the 3D representation of the 3D-aware GAN into a template field and a deformation field, where the former represents different identities with a canonical expression, and the latter characterizes expression variations of each identity. To achieve meaningful control over facial expressions via deformation, we propose a 3D-level imitative learning scheme between the generator and a parametric 3D face model during adversarial training of the 3D-aware GAN. This helps our method achieve high-quality animatable face image generation with strong visual 3D consistency, even though trained with only unstructured 2D images. Extensive experiments demonstrate our superior performance over prior works. 
Project page: <a href="https://yuewuhkust.github.io/AniFaceGAN"> https://yuewuhkust.github.io/AniFaceGAN. </a>
                </p>
            </div>
        </div>

<!--         <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Video
                </h2>
                <hr style="margin-top:0px">
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/Uqzs4uN6v8M" allowfullscreen=""
                            style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->
        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Overview
                </h2>
                <hr style="margin-top:0px">
                <img src="./files/overview.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify" style="font-size: 16px;">
                    Our proposed framework which consists of a template radiance field and an expression-driven deformation field for animatable 3D-aware face image generation.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
				<!--
                <h2>
                    Acknowledgements
                </h2>
				-->
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    The website template was adapted from <a href="https://yudeng.github.io/GRAM/">GRAM</a> and <a href="https://jonbarron.info/mipnerf/">Mip-NeRF</a>.
                </p>
            </div>
        </div>


</body>

</html>


